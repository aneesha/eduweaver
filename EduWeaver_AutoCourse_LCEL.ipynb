{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#EduWeaver\n",
        "\n",
        "EduWeaver uses ChatGPT API to make a LiaScript course. EduWeaver can be considered an AutoCourse maker.\n",
        "\n",
        "- Specify a topic and a few other parameters (i.e. sub-sections to nclude and exclude)\n",
        "- Creates a list of sub sections (or chapters)\n",
        "- Generates the content\n",
        "- Generates appropriate activities eg MCQ's\n",
        "- Adds simplified sections to explain complex things better\n",
        "- Includes external links or readings\n",
        "- Includes code snippets/examples for programming related topics\n",
        "- Saves as a Markdown file for valid [LiaScript](https://liascript.github.io/)\n",
        "\n",
        "Coming soon:\n",
        "\n",
        "- Additional interactive learning activities\n",
        "- Other export formats eg HTML and SCORM\n",
        "\n",
        "Eduweaver uses LangChain and the latest LangChain Expression Language (LCEL) syntax."
      ],
      "metadata": {
        "id": "4w68gwJB3gtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Enter a few details about the course and your OpenAI API key. You can create a new API key by going to your OpenAI Account [https://platform.openai.com/account/api-keys]."
      ],
      "metadata": {
        "id": "Htgj6fEB3Ji_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Course Generation Settings\n",
        "topic = 'Design Thinking'  #@param {type: \"string\"}\n",
        "teaching_method = 'Explain concepts is a simple and straight forward manner'  #@param {type: \"string\"}\n",
        "no_sub_topics = 8  #@param {type: \"slider\", min: 2, max: 10}\n",
        "sub_topics_to_include = \"Idea integration\" #@param {type: \"string\"}\n",
        "sub_topics_to_not_include = \"\" #@param {type: \"string\"}\n",
        "audience = 'Educators'   #@param {type: \"string\"}\n",
        "no_quiz_questions_in_sub_topic = 5 #@param {type: \"slider\", min: 1, max: 6}\n",
        "narrator_language = \"Australian Female\" #@param [\"UK English Female\", \"US English Female\", \"Australian Female\", \"UK English Male\", \"US English Male\", \"Australian Male\"]\n",
        "output_filename = 'DesignThinking_Course.md'  #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n"
      ],
      "metadata": {
        "id": "V15z77aE-d6F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8cYE0Rs3Vhi"
      },
      "outputs": [],
      "source": [
        "# Set your environment variables\n",
        "# Don't include quotes around the key\n",
        "%env OPENAI_API_KEY="
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install openai langchain"
      ],
      "metadata": {
        "id": "8XBQbatU5YIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b3e93d-6391-49db-cdb2-c4eebb7aadfc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.0.352-py3-none-any.whl (794 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.4/794.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
            "  Downloading langchain_community-0.0.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain)\n",
            "  Downloading langchain_core-0.1.3-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.70 (from langchain)\n",
            "  Downloading langsmith-0.0.75-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: typing-extensions, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-community, langchain\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.3 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.352 langchain-community-0.0.6 langchain-core-0.1.3 langsmith-0.0.75 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.6.1 typing-extensions-4.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
        "\n",
        "# Setup the model\n",
        "model = ChatOpenAI(temperature=0.7, model_name='gpt-4')\n",
        "json_output_parser = SimpleJsonOutputParser()\n",
        "string_output_parser = StrOutputParser()\n",
        "\n",
        "# Get TOC sections for the course\n",
        "\n",
        "print(\"- Getting Course TOC.\")\n",
        "\n",
        "# First extract the additional specified sub-sections\n",
        "list_of_additional_sub_sections = sub_topics_to_include.split(';')\n",
        "sub_topics_to_include_text = \" \"\n",
        "if len(list_of_additional_sub_sections) > 0:\n",
        "  sub_topics_to_include_text = \"In the sub sections also please include these: \" + sub_topics_to_include\n",
        "\n",
        "list_of_sub_topics_not_to_incude = sub_topics_to_not_include.split(';')\n",
        "sub_topics_to_not_include_text = \" \"\n",
        "if len(list_of_sub_topics_not_to_incude) > 0:\n",
        "  sub_topics_to_not_include_text = \"Please don't include content on these sub-topics (THIS IS VERY IMPORTANT): \" + sub_topics_to_not_include\n",
        "\n",
        "\n",
        "if teaching_method!=\"\":\n",
        "  teaching_method_to_include_text = \"Use this teaching and writing style: \" + teaching_method\n",
        "\n",
        "\n",
        "act_as_ld_template='''\n",
        "                      Please act as a subject matter expert on the topic of {topic}. You also have learning designer skills and knowledge of markdown and json.\n",
        "                      You know how to design online modules with a deep knowledge of the sections that need to be included for the topic. You can break up the content into chunks, explain concepts so that can easily be understood, write quizzes to test knowledge and write creative learning activities for students.\n",
        "                   '''\n",
        "ask_for_sections_template='''\n",
        "                              Could you please come up with {no_sub_topics} sections for an online module on the topic of {topic} for {audience} in json format?\n",
        "                              {sub_topics_to_include_text}\n",
        "                              {sub_topics_to_not_include_text}\n",
        "                              Here is an example of the format you need to return:\n",
        "                              [{{\"section_name\": \"The name of the section 1\", \"section_description\": \"The descriptions of the section 1\"}}]\n",
        "                              Note that you must only return the section_name and section_description fields in the json that is returned.\n",
        "                              Please don't return any intro text before or after the json. YOU MUST RETURN ONLY VALID JSON.\n",
        "                          '''\n",
        "\n",
        "toc_prompt = ChatPromptTemplate.from_template(act_as_ld_template + ask_for_sections_template)\n",
        "\n",
        "toc_chain = toc_prompt | model | json_output_parser\n",
        "\n",
        "sections = toc_chain.invoke({\"topic\": topic, \"no_sub_topics\": no_sub_topics, \"sub_topics_to_include_text\": sub_topics_to_include_text, \"sub_topics_to_not_include_text\": sub_topics_to_not_include_text, \"audience\": audience })\n",
        "\n",
        "updated_sections = []\n",
        "for section in sections:\n",
        "  new_section = {\"topic\": topic, \"no_sub_topics\": no_sub_topics, \"sub_topics_to_include_text\": sub_topics_to_include_text, \"sub_topics_to_not_include_text\": sub_topics_to_not_include_text, \"no_quiz_questions_in_sub_topic\":no_quiz_questions_in_sub_topic, \"audience\": audience, \"teaching_method_to_include_text\": teaching_method_to_include_text, \"section_name\": section[\"section_name\"], \"section_description\": section[\"section_description\"]}\n",
        "  updated_sections.append(new_section)\n",
        "\n",
        "# Get content for each sub section\n",
        "\n",
        "print(\"- Getting content for each sub section.\")\n",
        "\n",
        "section_details_template='''\n",
        "                              Could you please write the content for this section name: {section_name}\n",
        "                              The content must be appropriate for this audience: {audience}\n",
        "                              The description of the topic that you must write is {section_description}.\n",
        "                              {teaching_method_to_include_text}\n",
        "                              {sub_topics_to_not_include_text}\n",
        "                              Please first output the section name as a level 2 markdown eg ## {section_name}\n",
        "                              If the section is on programming or coding please include code examples within backticks and specify the language and filename eg:\n",
        "                              ``` js     +Filename.js\n",
        "                                  let hi = \"Hello World\"\n",
        "                              ```\n",
        "                              If the section needs math just place the Latex for the math equations between $ signs eg $ \\frac{{a}}{{\\sum{{b+i}}}} $\n",
        "                              You can include sub sections. Please place the sub section headings within ** and ** followed by \\n (eg **Goals** \\n ) as this is the markdown for sub sections at heading level 3 and a newline is required after.\n",
        "                              For difficult concept please include a section also \"**Additional Links**\" with links to Wikipedia and please make sure the proper markdown is used for links. Only include links to wikipedia that exist, don't include links to other sites (this is very important).\n",
        "                          '''\n",
        "\n",
        "author_sections_prompt = ChatPromptTemplate.from_template(act_as_ld_template + section_details_template)\n",
        "\n",
        "author_sections_chain = author_sections_prompt | model | string_output_parser\n",
        "\n",
        "sections_markdown = author_sections_chain.batch(updated_sections)\n",
        "\n",
        "# Get creative projects\n",
        "\n",
        "print(\"- Getting creative projects.\")\n",
        "\n",
        "creative_project_template='''\n",
        "                              Could you please come up with a few creative project ideas for {topic} that will be appropriate for {audience}?\n",
        "                              Be creative and the project should assist students in learning higher level skills that can't be obtained by doing multiple choice tests.\n",
        "                              The high level project ideas should develop levels from Blooms taxonomy including Application, Analysis, Synthesis, and Evaluation.\n",
        "                              Please don't output the section name or the type of level used from Blooms taxonomy but do include an introductory paragraph.\n",
        "                              {sub_topics_to_not_include_text}\n",
        "                              If the project for the section is on programming or coding please include code examples for the project within backticks and specify the language and filename eg:\n",
        "                              ``` js     +Filename.js\n",
        "                                  let hi = \"Hello World\"\n",
        "                              ```\n",
        "                              If the project for the section needs maths please place the Latex for the math equations between $ signs eg $ \\frac{{a}}{{\\sum{{b+i}}}} $\n",
        "                              Don't include quiz questions.\n",
        "                              Include each project as a sub sections in markdown. Please place the sub section headings within ** and ** followed by \\n (eg **Project 1** \\n ) as this is the markdown for sub sections at heading level 3 and a newline is required after.\n",
        "                          '''\n",
        "\n",
        "creative_project_prompt = ChatPromptTemplate.from_template(act_as_ld_template + creative_project_template)\n",
        "\n",
        "creative_project_chain = creative_project_prompt | model | string_output_parser\n",
        "\n",
        "creative_projects = creative_project_chain.invoke({\"topic\": topic, \"no_sub_topics\": no_sub_topics, \"sub_topics_to_include_text\": sub_topics_to_include_text, \"sub_topics_to_not_include_text\": sub_topics_to_not_include_text, \"audience\": audience })\n",
        "\n",
        "# Get Quiz Questions for each section\n",
        "\n",
        "print(\"- Getting quiz questions for each sub section.\")\n",
        "\n",
        "section_assessment_template='''\n",
        "                              Could you please write quiz questions for the content in {section_name} that will be appropriate for {audience}?\n",
        "                              The description of the topic that you must write quiz questions for is {section_description}.\n",
        "                              Please write {no_quiz_questions_in_sub_topic} questions in the json format that is given in the example below:\n",
        "\n",
        "                              [\n",
        "                                {{\"question\": \"Question 1\",\n",
        "                                 \"question_type\": \"single_option\",\n",
        "                                 \"options\": [{{\"option_name\": \"Option 1\", \"correct\": \"false\"}}, {{\"option_name\": \"Option 2\", \"correct\": \"true\"}}]\n",
        "                                }},\n",
        "                                {{\"question\": \"Question 2\",\n",
        "                                 \"question_type\": \"multiple_options\",\n",
        "                                 \"options\": [{{\"option_name\": \"Option 1\", \"correct\": \"false\"}}, {{\"option_name\": \"Option 2\", \"correct\": \"true\"}}, {{\"option_name\": \"Option 3\", \"correct\": \"true\"}} the]\n",
        "                                }}\n",
        "                              ]\n",
        "\n",
        "                              The questions must be returned in the same json format as what is given above. The incorrect answers should not be obvious or easy.\n",
        "                              Please note that you there are 2 types of questions namely single_option and multiple_options.\n",
        "                          '''\n",
        "\n",
        "assessment_prompt = ChatPromptTemplate.from_template(act_as_ld_template + section_assessment_template)\n",
        "\n",
        "assessment_chain = assessment_prompt | model | json_output_parser\n",
        "\n",
        "quiz_questions = assessment_chain.batch(updated_sections)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlZRArXPicoF",
        "outputId": "634930ac-1483-4e5b-f6e6-1630f8fecdfa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Getting Course TOC.\n",
            "- Getting content for each sub section.\n",
            "- Getting creative projects.\n",
            "- Getting quiz questions for each sub section.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Quiz Json to LiaScript Markdown\n",
        "print(\"- Convert MCQ Json to Liascript Markdown.\")\n",
        "\n",
        "quiz_questions = [[] if x is None else x for x in quiz_questions] # Makes None an empty list\n",
        "\n",
        "course_assessment_markdown = {}\n",
        "\n",
        "for index, quiz_section in enumerate(quiz_questions):\n",
        "  question_markdown = \"\"\n",
        "  #print(quiz_section)\n",
        "  for question in quiz_section:\n",
        "    question_title = question['question']\n",
        "    question_type = question['question_type']\n",
        "    if (question_type == \"single_option\"):\n",
        "      open_brace = '('\n",
        "      close_brace = ')'\n",
        "    else:\n",
        "      open_brace = '['\n",
        "      close_brace = ']'\n",
        "    question_markdown += question_title + '\\n\\n'\n",
        "    options = question['options']\n",
        "    for option in options:\n",
        "      option_name = option[\"option_name\"]\n",
        "      if option['correct'] == \"true\":\n",
        "        marker = 'X'\n",
        "      else:\n",
        "        marker = ' '\n",
        "      question_markdown += f'''    [{open_brace}{marker}{close_brace}] {option_name} \\n'''\n",
        "    question_markdown += '\\n'\n",
        "    section_name = sections[index]['section_name']\n",
        "    course_assessment_markdown[section_name] = question_markdown\n",
        "\n",
        "\n",
        "# Collate course and force download of the Markdown file\n",
        "\n",
        "print(\"- Collating course content.\")\n",
        "\n",
        "course_markdown = \"\"\n",
        "\n",
        "course_markdown += f\"\"\"\n",
        "<!--\n",
        "\n",
        "author:   EduWeaver - An AutoCourse Creator Using ChatGPT\n",
        "email:    nobody@nowhere.com\n",
        "version:  0.0.2\n",
        "language: en\n",
        "narrator: {narrator_language}\n",
        "\n",
        "logo:     https://liascript.github.io/img/bg-showcase-1.jpg\n",
        "\n",
        "comment:  Eduweaver generates course content using chatGPT and outputs in Liascript Markdown\n",
        "\n",
        "-->\n",
        "\"\"\"\n",
        "\n",
        "course_markdown += f'''# {topic}\\n'''\n",
        "\n",
        "# Make the TOC\n",
        "toc = \"In this course the following content will be covered: \\n\\n\"\n",
        "for section in sections:\n",
        "  section_name = section['section_name']\n",
        "  section_description = section['section_description']\n",
        "  toc += f'''- {section_name} \\n {section_description} \\n\\n'''\n",
        "\n",
        "course_markdown += \"\"\"\n",
        "> This course is completely generated by Eduweaver (using ChatGPT) in Liascript Markdown format.\n",
        "> Please verify the content before publishing the course. \\n \\n\n",
        "\"\"\"\n",
        "\n",
        "course_markdown += toc\n",
        "\n",
        "for index, section in enumerate(sections):\n",
        "  section_name = section['section_name']\n",
        "  section_description = section['section_description']\n",
        "  section_content = sections_markdown[index]\n",
        "  if section_name in course_assessment_markdown:\n",
        "    section_assessment = course_assessment_markdown[section_name]\n",
        "  else:\n",
        "    section_assessment = None\n",
        "\n",
        "  course_markdown += f'''{section_content}\\n\\n'''\n",
        "  if section_assessment!=None:\n",
        "    course_markdown += f'''### Quiz Questions \\n\\n'''\n",
        "    course_markdown += f'''{section_assessment}\\n'''\n",
        "\n",
        "course_markdown += f'''## Project Ideas \\n\\n'''\n",
        "course_markdown += f'''{creative_projects}\\n\\n'''\n",
        "\n",
        "with open(output_filename, 'w') as writefile:\n",
        "    writefile.write(course_markdown)\n",
        "\n",
        "print(\"- Forcing file download.\")\n",
        "from google.colab import files\n",
        "files.download(output_filename)\n",
        "\n",
        "print(\"- If the file does not download, click on the Folder on the left and you will be able to download manually.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "wWlms8i9dii4",
        "outputId": "9a46b84d-4ce2-4469-aabf-0e6bd2fd8609"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Convert MCQ Json to Liascript Markdown.\n",
            "- Collating course content.\n",
            "- Forcing file download.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dc812d9b-5c42-4817-8f17-6a6f6a428b27\", \"DesignThinking_Course.md\", 36749)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- If the file does not download, click on the Folder on the left and you will be able to download manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What to do next?\n",
        "\n",
        "- Place the markdown (.md) file on github and then view using the [Liascript Viewer](https://liascript.github.io/)\n",
        "OR\n",
        "- Copy the markdown content into the [Liascript LiveEditor](https://liascript.github.io/LiveEditor/) for editing and previewing."
      ],
      "metadata": {
        "id": "6sPrnraI2Nei"
      }
    }
  ]
}